% ============================================
% CERA Bibliography - Comprehensive Version
% 60+ references from top-tier venues
% CVPR, ICCV, ECCV, ICML, ICLR, NeurIPS, WACV, IEEE TPAMI, IEEE TIP
% ============================================

% ==========================================================
% SECTION 1: Large Vision-Language Models (15 papers)
% ==========================================================

@inproceedings{llava,
  title={{Visual Instruction Tuning}},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{llava15,
  title={{Improved Baselines with Visual Instruction Tuning}},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{llavanext,
  title={{LLaVA-NeXT: A Strong Zero-shot Video Understanding Model}},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Wang, Pengchuan and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@article{gpt4v,
  title={{GPT-4 Technical Report}},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{blip2,
  title={{BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2023}
}

@inproceedings{blip,
  title={{BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2022}
}

@inproceedings{clip,
  title={{Learning Transferable Visual Models From Natural Language Supervision}},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@inproceedings{flamingo,
  title={{Flamingo: a Visual Language Model for Few-Shot Learning}},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@inproceedings{instructblip,
  title={{InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning}},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{minigpt4,
  title={{MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models}},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{qwenvl,
  title={{Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond}},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{cogvlm,
  title={{CogVLM: Visual Expert for Pretrained Language Models}},
  author={Wang, Weihan and Shi, Qingsong and Lv, Qipeng and Zheng, Wenyi and Hong, Wenmeng and Ding, Ming and Tang, Jie},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{pali,
  title={{PaLI: A Jointly-Scaled Multilingual Language-Image Model}},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beez, Lucas and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{llama_adapter,
  title={{LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention}},
  author={Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{llava_med,
  title={{LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day}},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

% ==========================================================
% SECTION 2: Video Understanding (12 papers)
% ==========================================================

@inproceedings{videollama,
  title={{Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding}},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2023}
}

@inproceedings{sevila,
  title={{Self-Chained Image-Language Model for Video Localization and Question Answering}},
  author={Yu, Shoubin and Cho, Jaemin and Yadav, Prateek and Bansal, Mohit},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{vila,
  title={{VILA: On Pre-training for Visual Language Models}},
  author={Lin, Ji and Chen, Hongxu and Li, Wei and Han, Song and Zhu, Ligeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{videochat,
  title={{VideoChat: Chat-Centric Video Understanding}},
  author={Li, Kunchang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{videollava,
  title={{Video-LLaVA: Learning United Visual Representation by Alignment Before Projection}},
  author={Lin, Bin and Zhu, Bin and Ye, Yang and Ning, Munan and Jin, Peng and Yuan, Li},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2024}
}

@inproceedings{timechat,
  title={{TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding}},
  author={Ren, Shuhuai and Yao, Linli and Li, Shicheng and Sun, Xu and Hou, Lu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{video_chatgpt,
  title={{Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models}},
  author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2024}
}

@article{moviechat,
  title={{MovieChat: From Dense Token to Sparse Memory for Long Video Understanding}},
  author={Song, Enxin and Chai, Wenhao and Wang, Guanhong and Zhang, Yucheng and Zhou, Haoyang and Wu, Feiyang and Guo, Xun and Ye, Tian and Lu, Yan and Hwang, Jenq-Neng and Gao, Gaoang},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{slowfast,
  title={{SlowFast Networks for Video Recognition}},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{i3d,
  title={{Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset}},
  author={Carreira, Joao and Zisserman, Andrew},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{c3d,
  title={{Learning Spatiotemporal Features with 3D Convolutional Networks}},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2015}
}

@inproceedings{timesformer,
  title={{Is Space-Time Attention All You Need for Video Understanding?}},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

% ==========================================================
% SECTION 3: Efficient Vision Transformers & Token Pruning (15 papers)
% ==========================================================

@inproceedings{tome,
  title={{Token Merging: Your ViT But Faster}},
  author={Bolya, Daniel and Fu, Cheng-Yang and Dai, Xiaoliang and Zhang, Peizhao and Feichtenhofer, Christoph and Hoffman, Judy},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{dynamicvit,
  title={{DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification}},
  author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{evit,
  title={{Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations}},
  author={Liang, Youwei and Ge, Chongjian and Tong, Zhan and Song, Yibing and Wang, Jue and Xie, Pengtao},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}

@inproceedings{spvit,
  title={{SPViT: Enabling Faster Vision Transformers via Latency-aware Soft Token Pruning}},
  author={Kong, Zhenglun and Dong, Peiyan and Ma, Xiaolong and Meng, Xin and Niu, Wei and Sun, Mengshu and Shen, Xuan and Yuan, Geng and Ren, Bin and Tang, Hao and others},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{ats,
  title={{Adaptive Token Sampling For Efficient Vision Transformers}},
  author={Fayyaz, Mohsen and Koohpayegani, Soroush Abbasi and Jafari, Farnoush Rezaei and Somber{\o}n, Sunnie and Joze, Hamed Rezazadegan Tavakoli and Pirsiavash, Hamed and Gall, Juergen},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{fastervit,
  title={{FasterViT: Fast Vision Transformers with Hierarchical Attention}},
  author={Hatamizadeh, Ali and Yin, Hongxu and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{efficientvit,
  title={{EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention}},
  author={Liu, Xinyu and Peng, Houwen and Zheng, Naiyan and Yang, Yi and Hu, Han and Yuan, Yaowei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{deit,
  title={{Training data-efficient image transformers \& distillation through attention}},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@inproceedings{poolformer,
  title={{MetaFormer is Actually What You Need for Vision}},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{mobileformer,
  title={{Mobile-Former: Bridging MobileNet and Transformer}},
  author={Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Yuan, Lu and Liu, Zicheng and Bai, Xiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{levit,
  title={{LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference}},
  author={Graham, Ben and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{vit_survey,
  title={{A Survey on Vision Transformer}},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume={45},
  number={1},
  pages={87--110},
  year={2023}
}

@inproceedings{fastvqa,
  title={{FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling}},
  author={Wu, Haoning and Chen, Chaofeng and Hou, Jingyu and Liao, Liang and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{pvt,
  title={{Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions}},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}

@inproceedings{swin,
  title={{Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}

% ==========================================================
% SECTION 4: Vision Transformers & Attention (8 papers)
% ==========================================================

@inproceedings{vit,
  title={{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{attention,
  title={{Attention Is All You Need}},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@inproceedings{flash_attention,
  title={{FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@inproceedings{beit,
  title={{BEiT: BERT Pre-Training of Image Transformers}},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}

@inproceedings{mae,
  title={{Masked Autoencoders Are Scalable Vision Learners}},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{detr,
  title={{End-to-End Object Detection with Transformers}},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{sam,
  title={{Segment Anything}},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}

@inproceedings{dinov2,
  title={{DINOv2: Learning Robust Visual Features without Supervision}},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

% ==========================================================
% SECTION 5: Video Anomaly Detection (10 papers)
% ==========================================================

@inproceedings{ucfcrime,
  title={{Real-world Anomaly Detection in Surveillance Videos}},
  author={Sultani, Waqas and Chen, Chen and Shah, Mubarak},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{xdviolence,
  title={{Not Only Look, But Also Listen: Learning Multimodal Violence Detection Under Weak Supervision}},
  author={Wu, Peng and Liu, Jing and Shi, Yujia and Sun, Yujia and Shao, Fangtao and Wu, Zhaoyang and Yang, Zhiwei},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{rtfm,
  title={{Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning}},
  author={Tian, Yu and Pang, Guansong and Chen, Yuanhong and Singh, Rajvinder and Verjans, Johan W. and Carneiro, Gustavo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}

@inproceedings{anomalygpt,
  title={{AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models}},
  author={Gu, Zhaopeng and Zhu, Bingke and Zhu, Guibo and Chen, Yingying and Tang, Ming and Wang, Jinqiao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2024}
}

@inproceedings{holmes_vad,
  title={{Holmes-VAD: Towards Unbiased and Explainable Video Anomaly Detection via Multi-modal LLM}},
  author={Zhang, Huaxin and Xu, Xiaohao and Wang, Xiang and Zeng, Jialong and Li, Chuchu and Chen, Xiaonan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025}
}

@inproceedings{mist,
  title={{MIST: Multiple Instance Self-Training Framework for Video Anomaly Detection}},
  author={Feng, Jia-Chang and Hong, Fa-Ting and Zheng, Wei-Shi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{vad_survey,
  title={{A Survey on Deep Learning Based Video Anomaly Detection}},
  author={Nayak, Rashmika and Pati, Umesh Chandra and Das, Santos Kumar},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2021}
}

@inproceedings{mgfn,
  title={{MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection}},
  author={Chen, Yingxian and Liu, Zhengzhe and Zhang, Baoheng and Fok, Wilton and Qi, Xiaojuan and Wu, Yik-Chung},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2023}
}

@inproceedings{umil,
  title={{Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly Detection}},
  author={Lv, Hui and Zhou, Zhongqi and Chen, Rui and Zeng, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{vadclip,
  title={{VADCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection}},
  author={Wu, Peng and Zhou, Xuerong and Pang, Guansong and Sun, Yujia and Liu, Jing and Wang, Peng and Zhang, Yanning},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2024}
}

% ==========================================================
% SECTION 6: Object Detection (8 papers)
% ==========================================================

@article{yolo,
  title={{YOLOv8}},
  author={Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
  journal={GitHub repository},
  year={2023},
  note={\url{https://github.com/ultralytics/ultralytics}}
}

@inproceedings{yolov7,
  title={{YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors}},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{yolov6,
  title={{YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications}},
  author={Li, Chuyi and Li, Lulu and Jiang, Hongliang and Weng, Kaiheng and Geng, Yifei and Li, Liang and Ke, Zaidan and Li, Qingyuan and Cheng, Meng and Nie, Weiqiang and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year={2022}
}

@inproceedings{focal_loss,
  title={{Focal Loss for Dense Object Detection}},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}

@inproceedings{faster_rcnn,
  title={{Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2015}
}

@inproceedings{fcos,
  title={{FCOS: Fully Convolutional One-Stage Object Detection}},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019}
}

@inproceedings{centernet,
  title={{Objects as Points}},
  author={Zhou, Xingyi and Wang, Dequan and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={arXiv preprint arXiv:1904.07850},
  year={2019}
}

@inproceedings{dino_det,
  title={{DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection}},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel M and Shum, Heung-Yeung},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

% ==========================================================
% SECTION 7: Prompt Tuning & Efficient Fine-tuning (8 papers)
% ==========================================================

@inproceedings{lora,
  title={{LoRA: Low-Rank Adaptation of Large Language Models}},
  author={Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}

@article{coop,
  title={{Learning to Prompt for Vision-Language Models}},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision (IJCV)},
  year={2022}
}

@inproceedings{vpt,
  title={{Visual Prompt Tuning}},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{cocoop,
  title={{Conditional Prompt Learning for Vision-Language Models}},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{adapter,
  title={{Parameter-Efficient Transfer Learning for NLP}},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@inproceedings{prefix_tuning,
  title={{Prefix-Tuning: Optimizing Continuous Prompts for Generation}},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2021}
}

@inproceedings{qlora,
  title={{QLoRA: Efficient Finetuning of Quantized LLMs}},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{p_tuning,
  title={{GPT Understands, Too}},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2023}
}

% ==========================================================
% SECTION 8: Industrial Safety & Surveillance (6 papers)
% ==========================================================

@article{industrial_safety_survey,
  title={{Deep Learning for Visual Intelligence in Surveillance and Safety Systems: A Survey}},
  author={Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
  journal={ACM Computing Surveys},
  year={2023}
}

@article{construction_safety,
  title={{Computer Vision-based Construction Safety Monitoring on Sites: A Survey}},
  author={Fang, Yihai and Cho, Yong K. and Zhang, Sijie and Perez, Enrique},
  journal={Automation in Construction},
  year={2023}
}

@inproceedings{ppe_detection,
  title={{PPE Detection in Construction Sites Using Deep Learning}},
  author={Nath, Nipun D. and Behzadan, Amir H. and Paal, Stephanie G.},
  booktitle={Proceedings of the International Conference on Civil, Structural and Transportation Engineering},
  year={2020}
}

@article{video_surveillance_survey,
  title={{A Survey of Video Analytics for Smart Cities}},
  author={Tian, Yonghong and Zhang, Xinxin and Werghi, Naoufel and Abdullah, Azreen and others},
  journal={IEEE Access},
  year={2020}
}

@article{cctv_analytics,
  title={{Intelligent Video Surveillance: A Review through Deep Learning Techniques for Crowd Analysis}},
  author={Sreenu, Gedela and Durai, Saleem},
  journal={Journal of Big Data},
  year={2019}
}

@inproceedings{workplace_safety,
  title={{Towards Intelligent Construction: Real-time Safety Monitoring Using Edge AI}},
  author={Fang, Weili and Love, Peter E.D. and Luo, Hanbin and Ding, Lieyun},
  booktitle={Automation in Construction},
  year={2022}
}

% ==========================================================
% SECTION 9: Edge AI & Model Compression (6 papers)
% ==========================================================

@inproceedings{tensorrt,
  title={{TensorRT: High-performance Deep Learning Inference}},
  author={NVIDIA},
  booktitle={NVIDIA Developer Blog},
  year={2020}
}

@inproceedings{distillation,
  title={{Distilling the Knowledge in a Neural Network}},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  booktitle={NeurIPS Workshop on Deep Learning},
  year={2015}
}

@inproceedings{pruning,
  title={{Learning both Weights and Connections for Efficient Neural Networks}},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William J.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2015}
}

@article{quantization_survey,
  title={{A Survey of Quantization Methods for Efficient Neural Network Inference}},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2103.13630},
  year={2021}
}

@inproceedings{mobileone,
  title={{MobileOne: An Improved One Millisecond Mobile Backbone}},
  author={Vasu, Pavan Kumar Anasosalu and Gabriel, James and Zhu, Jeff and Tuzel, Oncel and Ranjan, Anurag},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{repvgg,
  title={{RepVGG: Making VGG-style ConvNets Great Again}},
  author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

% ==========================================================
% SECTION 10: Datasets & Benchmarks (5 papers)
% ==========================================================

@inproceedings{imagenet,
  title={{ImageNet: A Large-Scale Hierarchical Image Database}},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2009}
}

@inproceedings{coco,
  title={{Microsoft COCO: Common Objects in Context}},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2014}
}

@inproceedings{kinetics,
  title={{The Kinetics Human Action Video Dataset}},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  booktitle={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@inproceedings{activitynet,
  title={{ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding}},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}

@inproceedings{charades,
  title={{Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding}},
  author={Sigurdsson, Gunnar A. and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2016}
}

% ==========================================================
% SECTION 11: KV Cache Optimization & Sparse Attention
% ==========================================================

@article{fasa,
  title={{FASA: Frequency-Aware Sparse Attention}},
  author={Wang, Yifei and Wang, Yueqi and Yue, Zhenrui and Zeng, Huimin and Wang, Yong and Lourentzou, Ismini and Tu, Zhengzhong and Chu, Xiangxiang and McAuley, Julian},
  journal={arXiv preprint arXiv:2602.03152},
  year={2026}
}

@article{rope,
  title={{RoFormer: Enhanced Transformer with Rotary Position Embedding}},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024}
}

@inproceedings{snapkv,
  title={{SnapKV: LLM Knows What You are Looking for Before Generation}},
  author={Li, Yuhong and Huang, Yingbing and Yang, Bowen and Venkitesh, Bharat and Locatelli, Acyr and Ye, Hanchen and Cai, Tianle and Lewis, Patrick and Chen, Danqi},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024}
}

@article{h2o,
  title={{H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models}},
  author={Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\'e}, Christopher and Barrett, Clark and Wang, Zhangyang and Chen, Beidi},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{streamingllm,
  title={{Efficient Streaming Language Models with Attention Sinks}},
  author={Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{pyramidkv,
  title={{PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling}},
  author={Cai, Zefan and Zhang, Yichi and Gao, Bofei and Liu, Yuliang and Liu, Tianyu and Lu, Keming and Xiong, Wayne and Dong, Yue and Chang, Baobao and Hu, Junjie and Xiao, Wen},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2025}
}
