\documentclass[runningheads]{llncs}

% TODO FINAL: Comment out review mode for camera-ready.
\usepackage[review,year=2026,ID=*****]{eccv}
%\usepackage{eccv}

\usepackage{eccvabbrv}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[accsupp]{axessibility}

% TODO FINAL: switch to non-review hyperref option.
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=eccvblue]{hyperref}
%\usepackage{hyperref}

\begin{document}

\title{CERA: Causal Event Reasoning and Attribution for Real-Time Surveillance}
\titlerunning{CERA}

\author{Anonymous Authors}
\authorrunning{Anonymous Authors}
\institute{Anonymous Institution\\
\email{anonymous@eccv2026.org}}

\maketitle

\begin{abstract}
Real-time surveillance systems need more than anomaly flags or descriptive captions.
Operational response requires causal accounts that connect events, agents, and outcomes under strict latency constraints.
We introduce \textbf{CERA} (\textbf{C}ausal \textbf{E}vent \textbf{R}easoning and \textbf{A}ttribution), a framework direction for online surveillance analysis that prioritizes three requirements: causal fidelity, evidential grounding, and runtime efficiency.
This manuscript presents an initial formalization with a structured objective, an online output contract, and an evaluation protocol that jointly considers reasoning quality and deployment-time feasibility.
\keywords{Causal Event Reasoning, Attribution, Surveillance, Efficient Inference}
\end{abstract}

\section{Introduction}

\paragraph{Why Causality Matters in Surveillance.}
Modern surveillance models can detect anomalies or generate captions, but practical response requires more: a causal account of what happened, what triggered it, and which entities were responsible.
In safety-critical settings, this distinction affects intervention priority, accountability, and prevention planning.

\paragraph{Problem Setting.}
We consider online surveillance streams where decisions must be both timely and explainable.
For each event segment, the system should produce (1) an event statement, (2) an attribution statement linking causes to outcomes, and (3) supporting evidence references.
We refer to this objective as \textit{causal event reasoning and attribution}.

\paragraph{Current Gap.}
Existing pipelines are often optimized for a single objective~\cite{vad_survey,video_surveillance_survey}.
Detection-focused systems emphasize recall but provide limited causal structure~\cite{rtfm,mist,vadclip,anomalygpt,holmes_vad}.
Caption-focused systems can describe scenes fluently but often blur causality and agency~\cite{video_chatgpt,videollava,moviechat}.
Offline reasoning approaches are expressive but difficult to deploy with strict real-time constraints~\cite{timechat,moviechat}.

\paragraph{CERA.}
We introduce \textbf{CERA}, a framework direction for real-time causal event reasoning and attribution.
CERA is organized around three constraints: \textit{causal fidelity} (correct cause-effect structure), \textit{evidential grounding} (traceable support in observed frames), and \textit{runtime efficiency} (practical throughput for continuous streams).
This paper starts by fixing these requirements as first-class design targets.

\paragraph{Scope of This Draft.}
This manuscript is built from a clean-room start.
The current version includes a first method-level formalization and protocol-level experiment design.
Next iterations will expand concrete module implementations and larger-scale empirical validation.

\paragraph{Contributions.}
\begin{itemize}
    \item We define a real-time surveillance task for causal event reasoning and attribution with explicit outputs for event, cause, and evidence.
    \item We propose CERA as a framework direction centered on causal fidelity, evidential grounding, and runtime efficiency.
    \item We establish a starting evaluation perspective that jointly considers causal quality and deployment-time performance.
\end{itemize}

\section{Related Work}

\paragraph{Surveillance Anomaly Detection.}
Prior surveillance literature has made strong progress on anomaly detection under weak supervision, including benchmark construction and learning objectives that improve anomaly recall~\cite{vad_survey,ucfcrime,xdviolence,rtfm,mist}.
More recent adaptations of vision-language models improve semantic coverage for anomaly understanding~\cite{vadclip,anomalygpt,holmes_vad}.
However, most systems still optimize anomaly scoring or descriptive diagnosis, not explicit cause-outcome attribution with verifiable evidence links.

\paragraph{Video-Language Reasoning.}
General video-language systems provide richer temporal descriptions and dialogue-style interaction~\cite{video_chatgpt,videollava,timechat,moviechat}.
These advances are valuable for open-ended understanding, but they are not primarily designed around causal direction consistency, evidence attachment, or deployment-time abstention behavior required in online surveillance settings.

\paragraph{Position of CERA.}
CERA is not another captioning or anomaly-score variant.
It targets the missing intersection between surveillance deployment constraints and causal attribution requirements by enforcing structured outputs, evidence checks, and runtime-feasibility objectives in one contract.

\section{Method}

\subsection{Task Formulation}
Let a surveillance stream be $\mathcal{V}=\{\mathbf{X}_1,\mathbf{X}_2,\dots\}$, where $\mathbf{X}_t$ is the frame at time $t$.
The system identifies event windows $\mathcal{W}=\{[t_s^k,t_e^k]\}_{k=1}^{K}$ and outputs one structured report per window.

For each window $k$, CERA predicts
\begin{equation}
\hat{\mathbf{y}}_k = \{\hat{e}_k, \hat{\mathcal{A}}_k, \hat{\mathcal{E}}_k\},
\end{equation}
where $\hat{e}_k$ is the event statement, $\hat{\mathcal{A}}_k$ is a set of causal attribution tuples, and $\hat{\mathcal{E}}_k$ is an evidence index set.

Each attribution tuple is represented as
\begin{equation}
\hat{a}_{k,j}=(\hat{c}_{k,j}, \hat{r}_{k,j}, \hat{o}_{k,j}),
\end{equation}
where $\hat{c}_{k,j}$ is a candidate cause, $\hat{o}_{k,j}$ is an outcome, and $\hat{r}_{k,j}$ is the causal relation type.
The evidence set $\hat{\mathcal{E}}_k$ maps each tuple to supporting temporal spans or frame references.

\subsection{CERA Design Requirements}
CERA is designed around three joint requirements.

\paragraph{Causal Fidelity.}
Predictions should preserve cause-effect direction and avoid descriptive but non-causal statements.
Operationally, this means the attribution tuples should match reference causal structure, not only lexical overlap.

\paragraph{Evidential Grounding.}
Every attribution claim should be linked to observable evidence in the same event window.
Ungrounded claims are treated as low-trust outputs regardless of language fluency.

\paragraph{Runtime Efficiency.}
Inference must satisfy deployment latency constraints under continuous streams.
Given an end-to-end latency $L_{e2e}$ and deployment budget $L_{max}$, CERA should operate in the feasible region:
\begin{equation}
L_{e2e} \leq L_{max}.
\end{equation}

\subsection{Structured Objective}
We model CERA as maximizing a utility that balances causal quality, evidence quality, and runtime feasibility:
\begin{equation}
\mathcal{U} = \lambda_c S_c + \lambda_e S_e + \lambda_r S_r,
\end{equation}
where $S_c$ measures causal fidelity, $S_e$ measures evidence grounding quality, and $S_r$ measures runtime fitness.

For runtime fitness, we use a normalized score:
\begin{equation}
S_r = \min\left(1,\frac{L_{max}}{L_{e2e}}\right).
\end{equation}
This formulation encourages quality gains only when latency remains practical.

\subsection{Online Inference Contract}
Given an event window $\mathbf{X}_{t_s^k:t_e^k}$, CERA predicts:
\begin{equation}
\hat{\mathbf{y}}_k = \mathcal{F}_{\theta}\!\left(\mathbf{X}_{t_s^k:t_e^k}\right),
\end{equation}
with confidence score $p_k$.
To reduce high-confidence hallucination risk in safety contexts, CERA uses abstention:
\begin{equation}
\hat{\mathbf{y}}_k =
\begin{cases}
\mathcal{F}_{\theta}(\mathbf{X}_{t_s^k:t_e^k}) & \text{if } p_k \ge \tau_{conf},\\
\varnothing & \text{otherwise}.
\end{cases}
\end{equation}

This contract makes failure modes explicit and prevents forcing a causal narrative when evidence is weak.

\subsection{Output Schema and Validation}
For deployment integration, CERA exposes a fixed output schema:
\begin{equation}
\hat{\mathbf{y}}_k = \{\hat{e}_k,\hat{\mathcal{A}}_k,\hat{\mathcal{E}}_k,\hat{s}_k\},
\end{equation}
where $\hat{s}_k$ is a quality status flag (\texttt{valid}, \texttt{abstain}, or \texttt{insufficient\_evidence}).

Before returning \texttt{valid}, CERA applies two consistency checks:
\begin{equation}
\text{CausalCheck}(\hat{\mathcal{A}}_k)=1,\quad
\text{EvidenceCheck}(\hat{\mathcal{A}}_k,\hat{\mathcal{E}}_k)=1.
\end{equation}
The first check verifies direction-consistent tuples and relation admissibility.
The second check verifies whether each accepted tuple has linked observable support.
If either check fails, CERA downgrades output status to \texttt{insufficient\_evidence} and suppresses final attribution claims.

\subsection{Failure Taxonomy}
To keep failure analysis actionable, we partition output errors into three types:
\begin{itemize}
    \item \textbf{Causal Structure Violation}: cause-effect direction or relation type is wrong.
    \item \textbf{Evidence Support Failure}: claim is plausible but unsupported by linked evidence.
    \item \textbf{Runtime Budget Breach}: quality is acceptable but latency violates deployment budget.
\end{itemize}
This taxonomy maps directly to the three CERA requirements and guides where to improve: reasoning logic, evidence alignment, or system optimization.

\subsection{Module-Level Design}
We decompose CERA into four cooperative modules:
\begin{equation}
\hat{\mathbf{y}}_k =
\mathcal{M}_{ctrl}\!\left(
\mathcal{M}_{evd}\!\left(
\mathcal{M}_{attr}\!\left(
\mathcal{M}_{evt}\!\left(\mathbf{X}_{t_s^k:t_e^k}\right)\right)\right)\right).
\end{equation}
This decomposition keeps responsibilities explicit and aligns each module with one or more CERA requirements.

\paragraph{Event Proposal Module ($\mathcal{M}_{evt}$).}
The event proposal stage generates candidate temporal windows and tracked entities from the stream.
Its goal is high recall under bounded latency, producing a compact event context for downstream reasoning instead of processing the full stream at maximum cost.

\paragraph{Attribution Construction Module ($\mathcal{M}_{attr}$).}
Given event context, CERA builds a directed causal interaction graph
\begin{equation}
\mathcal{G}_k=(\mathcal{V}_k,\mathcal{E}_k^{c}),
\end{equation}
where nodes represent entities/outcomes and directed edges represent candidate causal relations.
Final attribution tuples are decoded from validated graph edges, enforcing direction consistency by construction.

\paragraph{Evidence Alignment Module ($\mathcal{M}_{evd}$).}
For each candidate tuple, CERA links supporting evidence spans in the same event window.
Each claim receives an evidence support score $q_{k,j}$ and is retained only if $q_{k,j}\ge\tau_{evd}$.
This stage prevents fluent but ungrounded attributions from passing as valid outputs.

\paragraph{Budget-Aware Control Module ($\mathcal{M}_{ctrl}$).}
The control module manages compute allocation and output policy under runtime budgets.
It applies adaptive depth, selective decoding, and abstention triggers to keep latency within $L_{max}$ while preserving causal and evidential quality.
When budget pressure is high, the controller prioritizes reliable partial outputs over unstable full attributions.

\subsection{Reference Instantiation (CERA-Ref)}
To make CERA implementation-ready, we define a reference stack (\textbf{CERA-Ref}) with concrete but replaceable components.

\paragraph{Event Backbone.}
CERA-Ref uses a lightweight one-stage detector (YOLOv8-Nano class) to produce risk-aware event proposals in real time.
For frame $\mathbf{X}_t$, the detector returns boxes $\mathcal{B}_t$ and risk scores $\mathcal{S}_t$, and triggers downstream reasoning only when the event score exceeds a gate threshold.

\paragraph{Reasoning Backbone.}
For attribution generation, CERA-Ref uses an open-source instruction-tuned 7B VLM with a 336px visual encoder setting.
This choice keeps the reasoning backbone reproducible while preserving enough capacity for causal language outputs.

\paragraph{Detection-Guided Token Compaction.}
Before attribution decoding, CERA-Ref applies detection-guided visual token selection:
\begin{equation}
\mathcal{T}^{keep}_t = \mathcal{T}(\mathcal{R}_t)\cup \mathcal{T}\!\left(\text{Dilate}(\mathcal{R}_t,\alpha)\right),
\end{equation}
where $\mathcal{R}_t$ is the detector-derived ROI set and $\alpha$ is a context dilation factor.
This keeps hazard-centric tokens and a thin context ring while pruning background-heavy regions.

\paragraph{Budgeted Decoding.}
During generation, CERA-Ref constrains active KV usage by a budget ratio $\rho_{kv}$:
\begin{equation}
K_{active} = \left\lceil \rho_{kv}\cdot K_{full}\right\rceil, \quad 0<\rho_{kv}\le1.
\end{equation}
The controller selects the top-$K_{active}$ entries via query-conditioned saliency and falls back to abstention or partial report if quality checks fail.

\subsection{Optimization Strategy}
CERA-Ref follows a staged optimization schedule that separates recall, reasoning, and runtime control.

\paragraph{Stage 1: Event Proposal Calibration.}
The detector is tuned with risk-aware weighting:
\begin{equation}
\mathcal{L}_{evt}=\sum_{c}\lambda_c\mathcal{L}^{(c)}_{det},
\end{equation}
where higher-risk classes use larger $\lambda_c$ to preserve recall on safety-critical events.

\paragraph{Stage 2: Attribution and Evidence Learning.}
Given triggered windows, the reasoning module optimizes attribution and evidence objectives jointly:
\begin{equation}
\mathcal{L}_{reason}=\mathcal{L}_{attr}+\gamma\mathcal{L}_{evd}.
\end{equation}
$\mathcal{L}_{attr}$ supervises relation direction/type and tuple content, while $\mathcal{L}_{evd}$ supervises support validity for each tuple.

\paragraph{Stage 3: Budget Controller Tuning.}
Controller parameters $(\tau_{conf},\tau_{evd},\rho_{kv})$ are tuned against deployment constraints by maximizing utility under latency limits:
\begin{equation}
\max \mathcal{U}\quad \text{s.t.}\quad L_{e2e}\le L_{max}.
\end{equation}
This stage determines the operating point between conservative abstention and aggressive throughput.

\subsection{Online Inference Procedure}
At deployment time, CERA-Ref runs the following sequence for each incoming stream window:
\begin{enumerate}
    \item run event proposal and gate non-event windows early,
    \item build attribution candidates from retained event context,
    \item attach evidence spans and compute support scores,
    \item apply schema and consistency checks,
    \item enforce runtime budget policy to output \texttt{valid}, \texttt{insufficient\_evidence}, or \texttt{abstain}.
\end{enumerate}
This pipeline operationalizes CERA as a deterministic contract rather than free-form generation.

\subsection{Current Scope}
This manuscript now defines CERA at task and objective levels with concrete module design.
It also specifies a reference instantiation for implementation.
The next stage is full implementation and empirical validation of each module under shared deployment constraints.

\section{Experiments}

\subsection{Evaluation Targets}
We evaluate CERA along three axes aligned with the method objective:
\begin{itemize}
    \item \textbf{Causal Quality}: correctness of predicted attribution tuples.
    \item \textbf{Evidence Quality}: correctness and completeness of linked evidence references.
    \item \textbf{Runtime}: end-to-end latency and effective throughput under fixed hardware.
\end{itemize}
As an initial benchmark substrate, we plan to start from established surveillance anomaly datasets~\cite{ucfcrime,xdviolence} and extend evaluation with attribution- and evidence-level annotations.

\subsection{Planned Metrics}
Let $\hat{\mathcal{A}}$ and $\mathcal{A}^{*}$ be predicted and reference attribution tuples, and let $\hat{\mathcal{E}}$ and $\mathcal{E}^{*}$ be predicted and reference evidence.
We plan to report:
\begin{itemize}
    \item tuple-level precision/recall/F1 for causal attribution,
    \item evidence precision/recall/F1 for grounding quality,
    \item end-to-end latency (ms), FPS, and stream capacity.
\end{itemize}

\subsection{Protocol Principles}
To keep comparisons meaningful, all compared systems will use the same runtime protocol:
hardware, input resolution, decoding length, and reporting policy.
Final claims will be tied to both quality metrics and latency feasibility under deployment budgets.

\subsection{Planned Ablations}
To validate each design choice, we plan a component-wise ablation suite:
\begin{itemize}
    \item \textbf{Full CERA-Ref}: event proposal + attribution + evidence alignment + budget controller.
    \item \textbf{No Event Gating}: process all windows to measure temporal-efficiency contribution.
    \item \textbf{No Token Compaction}: disable detection-guided token selection.
    \item \textbf{No Budgeted Decoding}: use dense decoding to isolate controller impact.
    \item \textbf{No Evidence Gate}: keep attribution without evidence-threshold filtering.
\end{itemize}
We will report both metric deltas and utility changes to reveal where quality--latency trade-offs originate.

\section{Conclusion}
This paper established \textbf{CERA} as a practical objective for real-time surveillance understanding: produce causal event reports that are structurally correct, evidentially grounded, and operationally feasible.
We formalized this objective through (1) a structured task definition, (2) a utility that balances causal quality, grounding quality, and runtime fitness, (3) an online contract with abstention and explicit status outputs, and (4) a concrete module-level design for event proposal, attribution construction, evidence alignment, and budget-aware control.
We also defined an initial evaluation protocol aligned with these requirements.

The next validation stage is empirical.
We plan to execute CERA-Ref end to end, run staged ablations, build annotated benchmarks for attribution and evidence linkage, and compare against detection- and caption-centric baselines under matched runtime settings.
This progression is intended to test whether causal reasoning quality can improve without violating deployment latency budgets.

\bibliographystyle{splncs04}
\bibliography{main}

\end{document}
