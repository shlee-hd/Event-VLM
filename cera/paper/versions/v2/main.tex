\documentclass[runningheads]{llncs}

% TODO FINAL: Comment out review mode for camera-ready.
\usepackage[review,year=2026,ID=*****]{eccv}
%\usepackage{eccv}

\usepackage{eccvabbrv}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[accsupp]{axessibility}

% TODO FINAL: switch to non-review hyperref option.
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=eccvblue]{hyperref}
%\usepackage{hyperref}

\begin{document}

\title{CERA: Causal Event Reasoning and Attribution for Real-Time Surveillance}
\titlerunning{CERA}

\author{Anonymous Authors}
\authorrunning{Anonymous Authors}
\institute{Anonymous Institution\\
\email{anonymous@eccv2026.org}}

\maketitle

\begin{abstract}
Real-time surveillance systems need more than anomaly flags or descriptive captions.
Operational response requires causal accounts that connect events, agents, and outcomes under strict latency constraints.
We introduce \textbf{CERA} (\textbf{C}ausal \textbf{E}vent \textbf{R}easoning and \textbf{A}ttribution), a framework direction for online surveillance analysis that prioritizes three requirements: causal fidelity, evidential grounding, and runtime efficiency.
This draft establishes the problem framing and design requirements as the foundation for method and evaluation development.
\keywords{Causal Event Reasoning, Attribution, Surveillance, Efficient Inference}
\end{abstract}

\section{Introduction}

\paragraph{Why Causality Matters in Surveillance.}
Modern surveillance models can detect anomalies or generate captions, but practical response requires more: a causal account of what happened, what triggered it, and which entities were responsible.
In safety-critical settings, this distinction affects intervention priority, accountability, and prevention planning.

\paragraph{Problem Setting.}
We consider online surveillance streams where decisions must be both timely and explainable.
For each event segment, the system should produce (1) an event statement, (2) an attribution statement linking causes to outcomes, and (3) supporting evidence references.
We refer to this objective as \textit{causal event reasoning and attribution}.

\paragraph{Current Gap.}
Existing pipelines are often optimized for a single objective.
Detection-focused systems emphasize recall but provide limited causal structure.
Caption-focused systems can describe scenes fluently but often blur causality and agency.
Offline reasoning approaches are expressive but difficult to deploy with strict real-time constraints.

\paragraph{CERA.}
We introduce \textbf{CERA}, a framework direction for real-time causal event reasoning and attribution.
CERA is organized around three constraints: \textit{causal fidelity} (correct cause-effect structure), \textit{evidential grounding} (traceable support in observed frames), and \textit{runtime efficiency} (practical throughput for continuous streams).
This paper starts by fixing these requirements as first-class design targets.

\paragraph{Scope of This Draft.}
This manuscript is built from a clean-room start.
The current version focuses on defining the CERA problem statement and system requirements before expanding to full method specification and large-scale experiments.

\paragraph{Contributions.}
\begin{itemize}
    \item We define a real-time surveillance task for causal event reasoning and attribution with explicit outputs for event, cause, and evidence.
    \item We propose CERA as a framework direction centered on causal fidelity, evidential grounding, and runtime efficiency.
    \item We establish a starting evaluation perspective that jointly considers causal quality and deployment-time performance.
\end{itemize}

\section{Method}

\subsection{Task Formulation}
Let a surveillance stream be $\mathcal{V}=\{\mathbf{X}_1,\mathbf{X}_2,\dots\}$, where $\mathbf{X}_t$ is the frame at time $t$.
The system identifies event windows $\mathcal{W}=\{[t_s^k,t_e^k]\}_{k=1}^{K}$ and outputs one structured report per window.

For each window $k$, CERA predicts
\begin{equation}
\hat{\mathbf{y}}_k = \{\hat{e}_k, \hat{\mathcal{A}}_k, \hat{\mathcal{E}}_k\},
\end{equation}
where $\hat{e}_k$ is the event statement, $\hat{\mathcal{A}}_k$ is a set of causal attribution tuples, and $\hat{\mathcal{E}}_k$ is an evidence index set.

Each attribution tuple is represented as
\begin{equation}
\hat{a}_{k,j}=(\hat{c}_{k,j}, \hat{r}_{k,j}, \hat{o}_{k,j}),
\end{equation}
where $\hat{c}_{k,j}$ is a candidate cause, $\hat{o}_{k,j}$ is an outcome, and $\hat{r}_{k,j}$ is the causal relation type.
The evidence set $\hat{\mathcal{E}}_k$ maps each tuple to supporting temporal spans or frame references.

\subsection{CERA Design Requirements}
CERA is designed around three joint requirements.

\paragraph{Causal Fidelity.}
Predictions should preserve cause-effect direction and avoid descriptive but non-causal statements.
Operationally, this means the attribution tuples should match reference causal structure, not only lexical overlap.

\paragraph{Evidential Grounding.}
Every attribution claim should be linked to observable evidence in the same event window.
Ungrounded claims are treated as low-trust outputs regardless of language fluency.

\paragraph{Runtime Efficiency.}
Inference must satisfy deployment latency constraints under continuous streams.
Given an end-to-end latency $L_{e2e}$ and deployment budget $L_{max}$, CERA should operate in the feasible region:
\begin{equation}
L_{e2e} \leq L_{max}.
\end{equation}

\subsection{Structured Objective}
We model CERA as maximizing a utility that balances causal quality, evidence quality, and runtime feasibility:
\begin{equation}
\mathcal{U} = \lambda_c S_c + \lambda_e S_e + \lambda_r S_r,
\end{equation}
where $S_c$ measures causal fidelity, $S_e$ measures evidence grounding quality, and $S_r$ measures runtime fitness.

For runtime fitness, we use a normalized score:
\begin{equation}
S_r = \min\left(1,\frac{L_{max}}{L_{e2e}}\right).
\end{equation}
This formulation encourages quality gains only when latency remains practical.

\subsection{Online Inference Contract}
Given an event window $\mathbf{X}_{t_s^k:t_e^k}$, CERA predicts:
\begin{equation}
\hat{\mathbf{y}}_k = \mathcal{F}_{\theta}\!\left(\mathbf{X}_{t_s^k:t_e^k}\right),
\end{equation}
with confidence score $p_k$.
To reduce high-confidence hallucination risk in safety contexts, CERA uses abstention:
\begin{equation}
\hat{\mathbf{y}}_k =
\begin{cases}
\mathcal{F}_{\theta}(\mathbf{X}_{t_s^k:t_e^k}) & \text{if } p_k \ge \tau_{conf},\\
\varnothing & \text{otherwise}.
\end{cases}
\end{equation}

This contract makes failure modes explicit and prevents forcing a causal narrative when evidence is weak.

\subsection{Current Scope}
This version defines CERA at the task and objective level.
Next iterations will specify the concrete module design (event proposal, attribution construction, evidence alignment, and budget-aware control) and their implementation details.

\section{Experiments}

\subsection{Evaluation Targets}
We evaluate CERA along three axes aligned with the method objective:
\begin{itemize}
    \item \textbf{Causal Quality}: correctness of predicted attribution tuples.
    \item \textbf{Evidence Quality}: correctness and completeness of linked evidence references.
    \item \textbf{Runtime}: end-to-end latency and effective throughput under fixed hardware.
\end{itemize}

\subsection{Planned Metrics}
Let $\hat{\mathcal{A}}$ and $\mathcal{A}^{*}$ be predicted and reference attribution tuples, and let $\hat{\mathcal{E}}$ and $\mathcal{E}^{*}$ be predicted and reference evidence.
We plan to report:
\begin{itemize}
    \item tuple-level precision/recall/F1 for causal attribution,
    \item evidence precision/recall/F1 for grounding quality,
    \item end-to-end latency (ms), FPS, and stream capacity.
\end{itemize}

\subsection{Protocol Principles}
To keep comparisons meaningful, all compared systems will use the same runtime protocol:
hardware, input resolution, decoding length, and reporting policy.
Final claims will be tied to both quality metrics and latency feasibility under deployment budgets.

\section{Conclusion}
\textbf{TODO.} Summarize findings and next validation steps.

\bibliographystyle{splncs04}
\bibliography{main}

\end{document}
