\documentclass[runningheads]{llncs}

% ---------------------------------------------------------------
% Include basic ECCV package
 
% TODO REVIEW: Insert your submission number below by replacing '*****'
% TODO FINAL: Comment out the following line for the camera-ready version
\usepackage[review,year=2026,ID=*****]{eccv}
% TODO FINAL: Un-comment the following line for the camera-ready version
%\usepackage{eccv}

% ---------------------------------------------------------------
% Other packages
\usepackage{eccvabbrv}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[section]{placeins}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[accsupp]{axessibility}

% ---------------------------------------------------------------
% Hyperref package
% TODO FINAL: Comment out the following line for the camera-ready version
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=eccvblue]{hyperref}
% TODO FINAL: Un-comment the following line for the camera-ready version
%\usepackage{hyperref}

\usepackage{orcidlink}

\newcommand{\Idom}{\mathcal{I}_{\text{dom}}}
\newcommand{\Ttop}{\mathcal{T}}

\begin{document}

% ---------------------------------------------------------------
\title{Event-VLM 2.0: TriAct Inference for Real-Time Explanation-Centric Safety Video Understanding}

\titlerunning{Event-VLM 2.0}

\author{Anonymous Authors}

\authorrunning{Anonymous Authors}

\institute{Anonymous Institution\\
\email{anonymous@eccv2026.org}}

\maketitle


% --- ABSTRACT ---
\begin{abstract}
We revisit real-time surveillance VLM deployment from an operations-first perspective: a practical system must maximize stream capacity while preserving explanation fidelity for safety-critical events. We frame this as \textit{tri-axis compute allocation}: decide computation \textit{when} to run (temporal), \textit{where} to focus (spatial), and \textit{what} to decode (memory bandwidth). We present \textbf{Event-VLM 2.0}, whose core algorithm \textbf{TriAct} combines: (1) risk-sensitive event gating, (2) hazard-aware adaptive token focusing, and (3) frequency-aware sparse decoding over RoPE frequency chunks. A lightweight hazard-priority prompt router recovers explanation quality with minimal latency overhead. 

On projected Draft-V2 targets under a unified runtime protocol, Event-VLM-Core reaches approximately \textbf{52.3 FPS} on UCF-Crime and \textbf{50.1 FPS} on XD-Violence, while retaining \textbf{99.1\%--99.9\% CIDEr} relative to the LLaVA-1.5 baseline. Cross-distribution extension to a ShanghaiTech-style protocol is projected to preserve the same speed-quality trend. We also specify a final statistical release protocol with multi-seed confidence intervals and paired significance tests. 

\textbf{Draft note:} numerical values in this version are projected placeholders and will be replaced by measured server-side results.

\keywords{Vision-Language Models, Efficient Inference, Surveillance, Token Pruning, KV Cache Optimization, Safety Monitoring}
\end{abstract}


% --- INTRODUCTION ---
\section{Introduction}

Modern vision-language models (VLMs) can explain scenes, not just recognize objects~\cite{llava,llava15,llavanext,blip,blip2,instructblip,minigpt4,gpt4v,pali}. For surveillance, this shift is operationally important: incident triage requires causal narratives (what happened, why risky, what next) rather than class labels.

The bottleneck is not raw model accuracy but \textit{inference economics}. A city-scale deployment may require hundreds of concurrent streams, strict latency bounds, and auditable outputs. In this regime, conventional frame-dense VLM inference becomes cost-prohibitive due to three independent redundancies:
\begin{itemize}
    \item \textbf{Temporal redundancy}: most frames contain no safety event;
    \item \textbf{Spatial redundancy}: most image tokens are irrelevant background;
    \item \textbf{Decoding redundancy}: full KV-cache access is memory-bandwidth dominated.
\end{itemize}

Prior work usually optimizes one axis at a time. Temporal filtering methods reduce frame count but still decode dense visual contexts~\cite{sevila}. Token pruning methods reduce vision compute but may drop small hazards~\cite{tome,dynamicvit,evit,ats,spvit}. KV optimizers accelerate language decoding but are mostly evaluated in text-centric settings~\cite{streamingllm,h2o,snapkv,pyramidkv,fasa}. As a result, end-to-end online throughput saturates early.

We propose \textbf{Event-VLM 2.0}, centered on \textbf{TriAct} inference. The key design principle is simple:
\begin{quote}
Allocate compute only when needed, where needed, and for cache entries that matter.
\end{quote}

\paragraph{Contributions.}
\begin{itemize}
    \item \textbf{Core idea}: a tri-axis formulation that unifies temporal gating, spatial token focusing, and decoding sparsity into one pipeline.
    \item \textbf{Method}: TriAct, with risk-sensitive event gating, morphology-aware adaptive dilation, and RoPE-frequency-driven sparse decoding.
    \item \textbf{Evaluation blueprint}: unified protocol + paired significance design + cross-distribution extension plan.
    \item \textbf{Projected draft outcome}: around 9--10$\times$ throughput gains with near-baseline explanation quality, to be validated with locked server runs.
\end{itemize}
Figure~\ref{fig:framework} summarizes the pipeline and interfaces. Projected operating points are reported in Tables~\ref{tab:main_ucf}, \ref{tab:main_xd}, and \ref{tab:main_sh}, with a consolidated frontier view in Figure~\ref{fig:frontier}. Component attribution and qualitative behavior are supported by Table~\ref{tab:ablation} and Figures~\ref{fig:components}--\ref{fig:qualitative}.


% --- RELATED WORK ---
\section{Related Work}

\subsection{Explanation-Centric VLMs}
Instruction-tuned VLMs have improved multimodal reasoning quality~\cite{llava,llava15,llavanext,blip,blip2,instructblip,minigpt4,qwenvl,cogvlm}. Video-oriented variants extend temporal understanding~\cite{videollama,videochat,videollava,video_chatgpt,moviechat,timechat,vila}, but deployment cost remains high under persistent online inference.

\subsection{Efficient Vision and Token Reduction}
Vision efficiency methods span architecture and token levels~\cite{vit,deit,swin,pvt,mae,dinov2,fastervit,efficientvit}. Token reduction methods such as DynamicViT, EViT, ToMe, and SPViT~\cite{dynamicvit,evit,tome,spvit} show strong speedups, but domain-agnostic pruning can remove small safety cues. Our method injects detection priors explicitly into token selection.

\subsection{Sparse Decoding and KV Optimization}
KV compression and eviction approaches (StreamingLLM, H2O, SnapKV, PyramidKV) target long-context decoding efficiency~\cite{streamingllm,h2o,snapkv,pyramidkv}. FASA observes functional sparsity in RoPE frequency chunks~\cite{fasa,rope}. We adapt this signal to mixed visual-textual decoding in surveillance VLMs.

\subsection{Anomaly Detection and Safety Monitoring}
Classical anomaly detection benchmarks and methods~\cite{ucfcrime,xdviolence,rtfm,mist,mgfn,umil,vad_survey} prioritize detection metrics. VLM-based anomaly reasoning methods improve explainability~\cite{anomalygpt,holmes_vad,vadclip}, but large-scale low-latency deployment remains underexplored. Safety-domain surveys emphasize this systems gap~\cite{industrial_safety_survey,construction_safety,cctv_analytics,video_surveillance_survey}.


% --- METHOD ---
\section{Method}

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.99\textwidth]{figures/figure1_architecture.png}
  \caption{\textbf{Event-VLM 2.0 (TriAct) overview.} The pipeline allocates compute across temporal, spatial, and decoding axes, followed by lightweight hazard-priority prompting.}
  \label{fig:framework}
\end{figure}
Figure~\ref{fig:framework} provides the stage-wise dataflow and shows where each efficiency axis acts.

\subsection{Core Idea: TriAxis Action (TriAct)}
Given surveillance stream $\mathcal{V}=\{\mathbf{X}_1,\mathbf{X}_2,\dots\}$, we compute captions $\mathbf{Y}_t$ only for frames that pass risk-aware gating:
\begin{equation}
\mathbf{Y}_t = \mathcal{F}_{\text{decode}}\Big(\mathcal{F}_{\text{gen}}(\mathcal{F}_{\text{focus}}(\mathbf{X}_t,\mathcal{B}_t)\mid \mathcal{P}_{\text{haz}})\Big),
\quad \text{if } \mathcal{F}_{\text{gate}}(\mathbf{X}_t)=1.
\end{equation}

\subsection{Stage 1: Risk-Sensitive Event Gating (Temporal)}
A lightweight detector predicts boxes $\mathcal{B}_t=\{b_k\}$ and scores $s_k$. We define frame risk score:
\begin{equation}
r_t = \max_k \; w(c_k)\, s_k,
\quad
\mathcal{F}_{\text{gate}}(\mathbf{X}_t)=\mathbb{I}(r_t>\tau_{\text{gate}}).
\end{equation}
Risk weights follow severity tiers (critical/high/standard). Detector training uses weighted focal loss:
\begin{equation}
\mathcal{L}_{\text{gate}} = \sum_k w(c_k)\,\mathcal{L}_{\text{focal}}(p_k,y_k).
\end{equation}

\subsection{Stage 2: Adaptive Token Focusing (Spatial)}
Let ViT produce $L$ patch tokens $\mathbf{Z}=\{z_i\}_{i=1}^{L}$. For each detected box $b_k$, dilation factor is class-conditioned:
\begin{equation}
\alpha_k = \alpha_{\text{base}} \left(1 + \beta\,\sigma_{\text{shape}}(c_k)\right).
\end{equation}
Here $\sigma_{\text{shape}}(c_k)\in[0,1]$ is normalized intraclass shape variance for class $c_k$, estimated from training annotations.
We build binary mask $\mathbf{M}\in\{0,1\}^{L}$ from dilated regions and keep:
\begin{equation}
\hat{\mathbf{Z}} = \{z_i\mid \mathbf{M}_i=1\}\cup\{z_{\text{cls}}\}.
\end{equation}
This reduces attention cost from $\mathcal{O}(L^2)$ to $\mathcal{O}(L'^2)$ with $L'\ll L$.

\subsection{Stage 3: Frequency-Aware Sparse Decoding (Decoding)}
Following RoPE functional sparsity~\cite{fasa,rope}, we calibrate dominant frequency-chunk sets $\Idom^{l,h}$ per head. During decoding step $t$:
\begin{equation}
\mathbf{S}^{l,h}_t = \sum_{i\in\Idom^{l,h}} \boldsymbol{\alpha}^{l,h,i}(\mathbf{q}_t,\mathbf{K}_{1:t}),
\quad
\Ttop_t=\operatorname{TopKIdx}(\mathbf{S}^{l,h}_t, N_{\text{fac}}).
\end{equation}
$\operatorname{TopKIdx}(\cdot, N_{\text{fac}})$ returns the index set of the top-$N_{\text{fac}}$ scores.
Full attention is computed only on gathered subset $(\hat{\mathbf{K}}_t,\hat{\mathbf{V}}_t)$ from $\Ttop_t$. The per-step complexity becomes:
\begin{equation}
\mathcal{O}(2tF + N_{\text{fac}}d),
\end{equation}
compared to dense $\mathcal{O}(2td)$.

\subsection{Stage 4: Hazard-Priority Prompt Routing (Adaptation)}
A small prompt bank switches between standard and critical templates:
\begin{equation}
\mathcal{P}_{\text{haz}}=
\begin{cases}
\mathcal{P}_{\text{critical}}, & \text{if } r_t>\tau_{\text{crit}},\\
\mathcal{P}_{\text{standard}}, & \text{otherwise}.
\end{cases}
\end{equation}
We set $\tau_{\text{crit}}\ge\tau_{\text{gate}}$ so that the critical template activates only for high-confidence hazard frames.
Only prompt parameters are updated in adaptation mode; backbone remains frozen.


% --- EXPERIMENTS ---
\section{Experiments}

\subsection{Draft Scope and Reporting Policy}
This manuscript version uses \textbf{projected numbers} to finalize narrative structure before locked server runs. Final camera-ready numbers will be replaced by measured outputs from multi-seed execution, CI estimation, and paired significance tests.

\subsection{Experimental Setup}
\paragraph{Datasets.}
We target three surveillance-style benchmarks:
\begin{itemize}
    \item \textbf{UCF-Crime}~\cite{ucfcrime};
    \item \textbf{XD-Violence}~\cite{xdviolence};
    \item \textbf{ShanghaiTech-style extension} (protocol-aligned split for cross-distribution validation).
\end{itemize}

\paragraph{Model and runtime.}
Backbone is LLaVA-1.5-7B~\cite{llava} with ViT-L/14-336 and Vicuna-7B. Trigger detector is YOLOv8-nano~\cite{yolo}. Dominant FC budget uses $F=16$ and $N_{\text{fac}}=256$.

\begin{table}[t]
\caption{\textbf{Unified runtime protocol} used for reproduced settings.}
\label{tab:protocol}
\centering
\setlength{\tabcolsep}{5pt}
\begin{tabular}{l|l}
\toprule
\textbf{Setting} & \textbf{Value} \\
\midrule
Hardware & 1$\times$ NVIDIA RTX 5080 \\
Precision & FP16 \\
Batch size & 1 \\
Frame sampling & 1 FPS \\
Resolution & 336px \\
Max generation length & 256 tokens \\
Runtime mode & Single-stream online \\
\bottomrule
\end{tabular}
\end{table}
All cross-method comparisons in this section follow the fixed protocol in Table~\ref{tab:protocol}.

\subsection{Main Results (Projected Draft Targets)}
Tables~\ref{tab:main_ucf}--\ref{tab:main_sh} report projected dataset-level comparisons under the same runtime settings.

\begin{table}[t]
\caption{\textbf{Projected main results on UCF-Crime}.}
\label{tab:main_ucf}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l|ccc}
\toprule
\textbf{Method} & \textbf{AUC (\%)} & \textbf{CIDEr} & \textbf{FPS} \\
\midrule
LLaVA-1.5 (baseline) & 85.0 & 90.1 & 5.2 \\
SeViLA & 84.6 & 88.2 & 12.3 \\
LLaVA + ToMe & 82.4 & 85.8 & 16.1 \\
LLaVA + SnapKV & 84.5 & 88.1 & 14.8 \\
\textbf{Event-VLM-Core (TriAct)} & \textbf{85.8} & 89.4 & \textbf{52.3} \\
\textbf{Event-VLM-Full} & 86.5 & \textbf{90.0} & 51.0 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\caption{\textbf{Projected main results on XD-Violence}.}
\label{tab:main_xd}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l|ccc}
\toprule
\textbf{Method} & \textbf{AUC (\%)} & \textbf{CIDEr} & \textbf{FPS} \\
\midrule
LLaVA-1.5 (baseline) & 83.7 & 86.4 & 5.2 \\
SeViLA & 83.2 & 84.9 & 12.1 \\
LLaVA + ToMe & 81.1 & 82.9 & 15.9 \\
LLaVA + SnapKV & 82.9 & 84.5 & 14.6 \\
\textbf{Event-VLM-Core (TriAct)} & \textbf{84.1} & 85.6 & \textbf{50.1} \\
\textbf{Event-VLM-Full} & 84.8 & \textbf{86.0} & 48.9 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\caption{\textbf{Projected cross-distribution trend on ShanghaiTech-style split}.}
\label{tab:main_sh}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l|ccc}
\toprule
\textbf{Method} & \textbf{AUC (\%)} & \textbf{CIDEr$^\dagger$} & \textbf{FPS} \\
\midrule
LLaVA-1.5 (baseline) & 82.6 & 84.2 & 5.1 \\
\textbf{Event-VLM-Core (TriAct)} & 83.4 & 83.5 & \textbf{49.0} \\
\textbf{Event-VLM-Full} & \textbf{84.0} & \textbf{84.0} & 47.8 \\
\bottomrule
\end{tabular}
\\[2pt]
{\footnotesize $^\dagger$ CIDEr evaluated on the caption-annotated subset only.}
\end{table}
Across UCF-Crime and XD-Violence targets, Core/Full preserve roughly 99.1\%--99.9\% CIDEr relative to baseline while improving throughput by about 9.4$\times$--10.1$\times$.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.99\textwidth]{figures/figure4_frontier.png}
  \caption{\textbf{Projected speed-quality frontier.} Event-VLM variants are expected to occupy the high-throughput, high-quality frontier region across datasets.}
  \label{fig:frontier}
\end{figure}
Figure~\ref{fig:frontier} visualizes the same operating points as a speed-quality frontier view.

\subsection{Statistical Plan and Expected Significance}
We will report mean$\pm$95\% CI across seeds \{41,42,43\}, and paired permutation tests against baseline on aligned video samples.

\begin{table}[t]
\caption{\textbf{Projected statistical summary format (example values).}}
\label{tab:stats_plan}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l|l|cc}
\toprule
\textbf{Dataset} & \textbf{Compare} & $\Delta$AUC (mean$\pm$CI) & $p$-value \\
\midrule
UCF-Crime & Core vs Baseline & +0.8 $\pm$ 0.3 & 0.012 \\
UCF-Crime & Full vs Baseline & +1.5 $\pm$ 0.4 & 0.004 \\
XD-Violence & Core vs Baseline & +0.4 $\pm$ 0.3 & 0.048 \\
XD-Violence & Full vs Baseline & +1.1 $\pm$ 0.4 & 0.009 \\
ShanghaiTech & Core vs Baseline & +0.8 $\pm$ 0.5 & 0.030 \\
ShanghaiTech & Full vs Baseline & +1.4 $\pm$ 0.5 & 0.011 \\
\bottomrule
\end{tabular}
\end{table}
Table~\ref{tab:stats_plan} defines the final reporting format only; camera-ready values will be replaced by auto-generated measured outputs.

\subsection{Ablation and Scaling (Projected)}
Table~\ref{tab:ablation} isolates how each TriAct axis contributes to speed-quality trade-offs.
\begin{table}[t]
\caption{\textbf{Projected TriAct ablation on UCF-Crime}.}
\label{tab:ablation}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{cccc|ccc}
\toprule
\textbf{Temp} & \textbf{Spatial} & \textbf{Decode} & \textbf{Prompt} & \textbf{FPS} & \textbf{AUC} & \textbf{CIDEr} \\
\midrule
- & - & - & - & 5.2 & 85.0 & 90.1 \\
\checkmark & - & - & - & 19.8 & 85.1 & 90.0 \\
\checkmark & \checkmark & - & - & 41.7 & 85.5 & 89.6 \\
\checkmark & \checkmark & \checkmark & - & \textbf{52.3} & 85.8 & 89.4 \\
\checkmark & \checkmark & \checkmark & \checkmark & 51.0 & \textbf{86.5} & \textbf{90.0} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\caption{\textbf{Projected robustness under heavier runtime protocol}.}
\label{tab:robustness}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{c|c|cc}
\toprule
\textbf{Resolution} & \textbf{Max Gen} & \textbf{CIDEr Retention} & \textbf{FPS Gain} \\
\midrule
224px & 128 & 99.3\% & 9.8$\times$ \\
336px & 256 & 99.0\% & 10.1$\times$ \\
448px & 384 & 98.6\% & 8.9$\times$ \\
\bottomrule
\end{tabular}
\end{table}
Table~\ref{tab:robustness} summarizes projected stability under heavier decoding budgets and resolutions.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/figure2_components.png}
  \caption{\textbf{TriAct component details.} Risk-sensitive weighting, adaptive dilation, and prompt routing preserve safety context under aggressive efficiency constraints.}
  \label{fig:components}
\end{figure}

\subsection{Qualitative Behavior}
Figure~\ref{fig:components} details module behavior, and Figure~\ref{fig:qualitative} illustrates qualitative token/decode patterns under projected settings.
\begin{figure}[t]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/figure3_pruning.png}
  \caption{\textbf{Projected qualitative behavior.} Token focusing keeps hazard-critical regions while sparse decoding maintains safety-relevant attention paths.}
  \label{fig:qualitative}
\end{figure}

\subsection{Limitations of This Draft}
Current evidence has three limitations. First, main quantitative values are projected placeholders pending locked server execution. Second, CI and paired significance values in Table~\ref{tab:stats_plan} are example-format entries until auto-generated artifacts are produced. Third, cross-distribution results on the ShanghaiTech-style protocol should be interpreted as extension targets until measured outputs are integrated.


% --- CONCLUSION ---
\section{Conclusion}
We proposed Event-VLM 2.0 with TriAct inference, a tri-axis systems design for explanation-centric surveillance VLMs. The central claim is not a single-module optimization, but a compositional pipeline that jointly addresses when to compute, where to compute, and what to decode.

In projected Draft-V2 values, TriAct sustains near-baseline explanation quality while improving throughput by roughly one order of magnitude. The final version will replace projected numbers with locked server measurements, including three-dataset multi-seed confidence intervals and paired significance reports. If those measurements track the projected trend, Event-VLM 2.0 will provide a practical blueprint for large-scale, real-time safety monitoring with explainable outputs.


% ---- Bibliography ----
\bibliographystyle{splncs04}
\bibliography{main}


% ============================================
% APPENDIX
% ============================================
\appendix

\section{Reproducibility and Execution Plan}

\subsection{One-Click Command (Server)}
\texttt{BENCHMARK\_CONFIGS=experiments/configs/ucf\_crime.yaml,experiments/configs/xd\_violence.yaml,experiments/configs/shanghaitech.yaml VARIANTS=none,core,full SIGNIFICANCE=1 SIGNIFICANCE\_BASELINE=none SIGNIFICANCE\_CANDIDATES=core,full RENDER\_PAPER\_TABLES=1 bash scripts/server\_ready\_one\_click.sh}

\subsection{Generated Artifacts}
Expected outputs after server execution:
\begin{itemize}
    \item Multi-seed summary: \texttt{outputs/.../summary.json}, \texttt{summary.md}
    \item Significance reports: \texttt{outputs/.../significance/*/significance.json}
    \item Paper-ready tables: \texttt{paper/generated/table\_multiseed\_overview.tex}
    \item Paper-ready tables: \texttt{paper/generated/table\_significance\_summary.tex}
\end{itemize}

\section{Method Hyperparameters (Draft Targets)}
\begin{table}[ht]
\centering
\setlength{\tabcolsep}{5pt}
\begin{tabular}{l|l}
\toprule
\textbf{Item} & \textbf{Value} \\
\midrule
$\tau_{\text{gate}}$ & 0.5 \\
Risk weights (critical/high/standard) & 3.0 / 2.0 / 1.0 \\
$\alpha_{\text{base}}$, $\beta$ & 1.2, 0.5 \\
Dominant FC budget $F$ & 16 (25\% of 64 FCs) \\
Focused tokens $N_{\text{fac}}$ & 256 \\
Prompt length per bank & 8 \\
\bottomrule
\end{tabular}
\caption{Draft hyperparameter targets for final run locking.}
\end{table}

\section{Figure Plan (Publication Layout)}
\begin{table}[ht]
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l|p{7.1cm}|l}
\toprule
\textbf{Figure} & \textbf{Purpose} & \textbf{Status} \\
\midrule
Fig. 1 & Core concept: tri-axis architecture and dataflow & Ready \\
Fig. 2 & Component mechanism detail (loss/dilation/prompt routing) & Ready \\
Fig. 3 & Qualitative token+decoding behavior & Ready \\
Fig. 4 & Speed-quality frontier (cross-dataset) & Ready \\
\bottomrule
\end{tabular}
\caption{Figure strategy aligned to narrative flow: concept $\rightarrow$ quantitative frontier $\rightarrow$ mechanism $\rightarrow$ qualitative evidence.}
\end{table}

\section{Table Plan (Camera-Ready)}
\begin{table}[ht]
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l|p{6.8cm}|l}
\toprule
\textbf{Table} & \textbf{Role} & \textbf{Source} \\
\midrule
Table~\ref{tab:protocol} & Unified protocol fairness anchor & Fixed text \\
Table~\ref{tab:main_ucf}, \ref{tab:main_xd}, \ref{tab:main_sh} & Main performance claims & Projected now, measured later \\
Table~\ref{tab:stats_plan} & Statistical reporting structure & Auto-generated target \\
Table~\ref{tab:ablation} & Axis-wise contribution & Projected now, measured later \\
Table~\ref{tab:robustness} & Runtime robustness & Projected now, measured later \\
\bottomrule
\end{tabular}
\caption{Planned table governance for draft-to-final transition.}
\end{table}

\section{Auto-Generated Statistical Tables}
\IfFileExists{generated/table_multiseed_overview.tex}{
  \input{generated/table_multiseed_overview.tex}
}{
  \begin{table}[ht]
  \centering
  \caption{Placeholder for auto-generated multi-seed overview table.}
  \label{tab:auto_multiseed_overview_placeholder}
  \begin{tabular}{l}
  \toprule
  Pending server execution: `paper/generated/table\_multiseed\_overview.tex` \\
  \bottomrule
  \end{tabular}
  \end{table}
}

\IfFileExists{generated/table_significance_summary.tex}{
  \input{generated/table_significance_summary.tex}
}{
  \begin{table}[ht]
  \centering
  \caption{Placeholder for auto-generated paired significance summary table.}
  \label{tab:auto_significance_summary_placeholder}
  \begin{tabular}{l}
  \toprule
  Pending server execution: `paper/generated/table\_significance\_summary.tex` \\
  \bottomrule
  \end{tabular}
  \end{table}
}

\end{document}
